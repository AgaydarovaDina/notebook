# -*- coding: utf-8 -*-
"""Итоговое задание.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/148eYuxDByyt9hZrDOGNmsrImwDmSqEwo

1. satisfaction_level - Уровень удовлетворенности работой
2. Last_evaluation - Время с момента последней оценки в годах
3. number_projects - Количество проектов, выполненных за время работы
4. average_monthly_hours - Среднее количество часов на рабочем месте в месяц
5. time_spend_company - Стаж работы в компании в годах
6. work_accident - Происходили ли несчастные случаи на рабочем месте с сотрудником
7. left - уволился ли сотрудник
8. promotion_last_5years - повышался ли сотрудник за последние пять лет
9. department - отдел в котором работает сотрудник
10. salary - относительный уровень зарплаты

**Задание 1.** Прочитаем файл
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as st

df = pd.read_csv('HR.csv')
df.head()

df.info()

"""**Задание 2.** Расчитем основным статистические показатели"""

#Перед расчетом убедимся, что данные корреткные и нет необходимости в очистке данных
df.isnull().sum()

df.describe()

"""**Задание 3.** Расчитаем и проанализируем корелляционную матрицу

satisfaction_level - **количественный**

Last_evaluation - качественный

number_projects - **количественный**

average_monthly_hours - **количественный**

time_spend_company - **количественный**

work_accident - качественный

left - качественный

promotion_last_5years - качественный

department - качественный

salary - качественный
"""

corr_matrix_pearson = df[['satisfaction_level',  'number_project', 'average_montly_hours', 'time_spend_company']].corr()
plt.figure(figsize=[8,5])
sns.heatmap(corr_matrix_pearson, annot=True, cmap='Greens')
plt.title("Матрица корреляции Пирсона")
plt.show()

"""На графике видно, что колчечество проектов и время на рабочем месте находятся в достаточно высокой зависимости, что в целм логично. Также количество проектов достоточно сильно зависит от стажа в компании, что тоже логчино.
Уровень удовлентворенности работой практически не зависит от времени, проведнного за рабочим местом, стажа в компании и количества проектов. Стаж работы в компании также не зависит от времени, проведенным за рабочим местом.

**Задание 4.** Расчитаем сколько сотрудников работает в каждом отделе
"""

df['department'].value_counts()

"""**Задание 5**. Покажем распределение сотрудников по зарплате"""

plt.figure(figsize=[7,5])
sns.countplot(data=df, x="salary", color="green")
plt.title("Количество сотрудников по уровню зарплаты")
plt.show()

"""**Задание 6.** Покажем распределение по уровню зарплаты в каждом департаменте по отдельности"""

pd.crosstab(df['department'], df['salary'], margins=True)

"""**Задание 7.** Проверим гипотезу, что сотрудники с большим окладом проводят на работе больше времени, чем сотрудники с более низким окладом."""

data_high = df.loc[df['salary']=='high']['average_montly_hours'].values
data_medium = df.loc[df['salary']=='medium']['average_montly_hours'].values
data_low = df.loc[df['salary']=='low']['average_montly_hours'].values

#проверим нормальность распределения данных
stat, p = st.shapiro(data_low)

print(f'stat = {stat:.3f}, p = {p:.5f}')
if p > 0.05:
    print('Вероятно нормальное распределение')
else:
    print('Вероятно не нормальное распределение')

#проверим равенство вариаций
stat, p = st.levene(data_high,data_medium,data_low)

print(f"Статистика = {stat:.5f}, p = {p:.5f}")

if p <0.05:
    print("Отклоняем нулевую гипотезу >> Вариация в группах раличается")
else:
    print("Не отклоняем нулевую гипотезу >> Вариация в группах одинаковая")

#проводим однофакторный дисперсионный анализ
fvalue, pvalue = st.f_oneway(data_high,data_medium,data_low)

print(f"Статистика = {fvalue:.5f}, p = {pvalue:.5f}")

if pvalue > 0.05:
    print('Не отклоняем нулевую гипотезу, средние, вероятно, одинаковые')
else:
    print('Отклоняем нулевую гипотезу, средние, вероятно, различаются')

"""**Вывод**. Тест не показал наличие статистически значимой разницы между зарплатой и времем работы

**Задание 8**. Рассчитать следующие показатели среди уволившихся и не
уволившихся сотрудников (по отдельности):

● Доля сотрудников с повышением за последние 5 лет

● Средняя степень удовлетворенности

● Среднее количество проектов
"""

df.groupby('left')['promotion_last_5years'].sum() / df['promotion_last_5years'].count()

df.groupby('left')['satisfaction_level'].mean()

df.groupby('left')['number_project'].mean()

"""**Задание 9**. Разделить данные на тестовую и обучающую выборки
Построить модель LDA, предсказывающую уволился ли
сотрудник на основе имеющихся факторов (кроме department и
salary)
Оценить качество модели на тестовой выборки
"""

df.drop(['salary', 'department'], axis=1)
df.head()

data_class = df['left']. to_numpy ()
data_class

from sklearn.model_selection import train_test_split
# разделяем выборку на тренировочную и тестовую
X_train, X_test, y_train, y_test = train_test_split(df, data_class, test_size=0.25, random_state=42)
len(y_test)
# импортируем LDA-функционал
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
lda = LinearDiscriminantAnalysis()
# обучаем данные
lda.fit(X_train, y_train)
# делаем прогноз на тестовой выборке
lda.predict(X_test)
# смотрим разницу факта и прогноза
result = pd.DataFrame([y_test, lda.predict(X_test)]).T

result

from sklearn.metrics import accuracy_score

accuracy_score(y_test, lda.predict(X_test))

# коэффициенты дискриминатных линий
lda.coef_